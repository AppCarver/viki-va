# Component Specification: `OutputManager`

**1. Component Name:** `OutputManager`

**2. Conceptual Role / Nickname:** Voice/Display Adapter / Delivery Agent / The "Speaker" / The "Broadcaster"

**3. Purpose / Mission:**
The `OutputManager` is the final conduit for the virtual assistant's responses. Its mission is to receive the natural language text generated by the `brain:language_center` (orchestrated by the `brain:pre-frontal_cortex`) and deliver it reliably and appropriately to the user's specific `Device`. It handles various output modalities (text, voice, rich media) and adapts the response format based on the target device's capabilities.

---

**4. Core Responsibilities:**

* **Response Reception:** Receive the finalized `va_response_text` from the `brain:pre-frontal_cortex`.
* **Device Identification & Lookup:** Identify the target `Device` (platform, channel, specific device instance) using `device_id` and retrieve its capabilities and configuration (e.g., supports rich text, requires TTS, specific API endpoint).
* **Output Channel Selection:** Select the appropriate external communication channel or adapter based on the `Device` type (e.g., SMS gateway, chat platform API, smart speaker SDK).
* **Content Adaptation & Formatting:** Transform the raw `va_response_text` into the format suitable for the target `Device` and channel. This may include:
    * Converting text to **Speech (Text-to-Speech - TTS)**.
    * Adding rich UI elements (buttons, cards, images) if the platform supports them (though the instruction for *what* rich elements to add might come from `pre-frontal_cortex` in `response_content`).
    * Formatting for specific messaging protocols.
* **Response Delivery:** Send the formatted response through the selected output channel to the user's `Device`.
* **Delivery Status Monitoring (Optional):** Monitor the status of the delivery (e.g., message sent, message delivered, TTS stream started).
* **Error Handling:** Manage and report errors encountered during content adaptation or delivery (e.g., TTS engine failure, network issues, invalid device ID).
* **User Preferences (Optional):** Incorporate user-specific output preferences (e.g., preferred voice, text size, notification settings) retrieved from `brain:long_term_mem`. **Crucially, these preferences in `long_term_mem` should be managed with dedicated retention policies to prevent accidental deletion or decay during archival maintenance.**

---

**5. External Interfaces / APIs:**

The `OutputManager` primarily exposes one API for the `pre-frontal_cortex` to send responses:

* `send_response(conversation_id, user_id, device_id, va_response_text, output_format_hints=None)`

#### API Definition: `send_response`

* **Description:** Delivers a natural language response to a specified user device, adapting it to the device's capabilities.
* **Parameters:**
    * `conversation_id` (`UUID`): The ID of the conversation.
    * `user_id` (`UUID`): The ID of the user to whom the response is addressed.
    * `device_id` (`str`): A unique identifier for the specific device or communication channel (e.g., a phone number, a chat platform ID, a smart speaker instance ID). This links to the `Device` registry.
    * `va_response_text` (`str`): The final natural language text generated by the `brain:language_center`.
    * `output_format_hints` (`dict`, optional): Additional hints from `pre-frontal_cortex` regarding desired output formatting (e.g., `{'tts_voice': 'female_1', 'rich_ui_elements': [{'type': 'button', 'text': 'Yes', 'value': 'yes'}]}`).
* **Returns:** (`dict`) A dictionary indicating the outcome of the delivery attempt:
    ```json
    {
        "success": true,              // Boolean indicating if the response was sent/queued for delivery.
        "delivery_status": "string",  // e.g., "SENT", "QUEUED", "DELIVERED" (if status tracking is available)
        "message_id": "string",       // (Optional) ID from the messaging platform.
        "error": {                    // (Optional) Dictionary if success is False.
            "code": "string",         // e.g., "DEVICE_UNREACHABLE", "TTS_FAILURE", "INVALID_FORMAT"
            "message": "string",      // Human-readable error description
            "details": "string"       // Optional, technical details.
        }
    }
    ```
* **Possible Errors (Internal to OutputManager):**
    * `DeviceNotFoundError`: `device_id` not found in the Device registry.
    * `UnsupportedOutputError`: `device_id`'s capabilities don't match requested `output_format_hints`.
    * `TTSConversionError`: Failure during text-to-speech conversion.
    * `DeliveryChannelError`: Issues sending via the specific platform API (e.g., network error, authentication failure).

---

**6. Internal Logic / Algorithm (Detailed Steps for `send_response`):**

* **Step 1: Retrieve Device Configuration:**
    * Lookup `device_id` in an internal "Device Registry" or a `Device` data store.
    * Get `device_type` (e.g., "SMS", "SmartSpeaker", "WebChat", "MobileApp"), associated API credentials, and capabilities (e.g., `can_do_tts`, `supports_rich_ui`).
    * IF `device_id` not found: Return `DeviceNotFoundError`.
* **Step 2: Apply User Preferences (Optional):**
    * IF `user_id` is provided: Query `brain:long_term_mem` for user-specific output preferences (e.g., preferred TTS voice, language locale, notification preferences). Merge these with `output_format_hints`. Implement robust fallback to default settings if a user preference is not found or is invalid.
* **Step 3: Content Adaptation:**
    * IF `device_type` is voice-based (`SmartSpeaker`, phone call) AND `output_format_hints` don't forbid:
        * Call a **Text-to-Speech (TTS) Engine/API** with `va_response_text` and preferred voice.
        * Receive `audio_stream` or `audio_file_url`.
        * IF TTS fails: Return `TTSConversionError`.
    * ELSE IF `device_type` supports rich UI:
        * Format `va_response_text` and `output_format_hints.rich_ui_elements` into the platform-specific message format (e.g., JSON payload for Slack, structured message for mobile app).
    * ELSE (simple text-based `Device`): Use `va_response_text` directly.
* **Step 4: Delivery Channel Invocation:**
    * Based on `device_type`, call the appropriate external SDK/API:
        * For SMS: Call Twilio/Nexmo API.
        * For Smart Speaker: Use Alexa/Google Assistant SDK to play audio or send a directive.
        * For Web Chat: Send WebSocket message or HTTP POST to chat server.
        * For Mobile App: Push notification or direct API call.
    * Handle authentication for the channel.
* **Step 5: Process Delivery Result:**
    * Capture response from the external channel (e.g., message ID, success/failure).
    * Return a structured result indicating `success`, `delivery_status`, and any `error`.

---

**7. Data Interactions:**

* **Reads from:**
    * **Device Registry / `Device` Data Model:** (An internal data store or configuration) to get `device_id` mappings, capabilities, and channel credentials.
    * **`brain:long_term_mem`**: For user-specific output preferences (e.g., preferred voice, notification settings), ensuring these are stored with appropriate, long-term retention policies.
* **Writes to:**
    * **External Messaging/Speech Platforms:** This is the primary output, transmitting the response to the user's `Device`.
    * **Logging System:** For auditing message delivery and errors.

---

**8. Dependencies:**

* **Text-to-Speech (TTS) Engine/API:** (e.g., Google Cloud Text-to-Speech, AWS Polly, ElevenLabs, or an on-premise solution).
* **Messaging Platform SDKs/APIs:** (e.g., Twilio, Slack API, WhatsApp API, Discord API, etc.).
* **Smart Speaker SDKs/APIs:** (e.g., Amazon Alexa Voice Service, Google Assistant SDK).
* **`Device` Data Store/Registry:** A persistent store for mapping `device_id` to its type, capabilities, and necessary credentials/configs.
* **Logging Framework:** For auditing and error reporting.
* **Credential Management System:** (As discussed for `ActionExecutor`) for storing API keys for TTS and messaging platforms.

---

**9. Assumptions / Constraints:**

* A **`Device` data model/registry** exists and is maintained, containing the necessary information for each `device_id`.
* Appropriate API keys/credentials for all external output channels and TTS services are securely managed and accessible.
* The `va_response_text` received from `language_center` is the final, well-formed natural language output. Any complex formatting (like rich UI elements) is passed as `output_format_hints` from `pre-frontal_cortex`.
* The `OutputManager` does not *decide* what to say, only *how* to deliver it. The `pre-frontal_cortex` makes the content decisions.
* **User preferences in `brain:long_term_mem` are stored with specific, long-term retention policies** to prevent accidental deletion during memory archival or decay processes. The system should also have fallback defaults if a preference is unavailable.
* Scalability for high-volume message delivery to various channels is a key consideration.